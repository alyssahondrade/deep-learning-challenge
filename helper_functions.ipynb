{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12940701-4d6d-4fb5-91e9-3f11c9c683da",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd9c78c-29fb-4182-a344-ec8631181e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_unique(df, max_value, columns_to_limit):\n",
    "    \"\"\"\n",
    "    Purpose of the function is to limit the number of unique values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each column\n",
    "    for col in columns_to_limit:\n",
    "        # Get the value counts of the column\n",
    "        total_counts = df[col].value_counts()\n",
    "        \n",
    "        # Get the top values to retain, not including \"Other\"\n",
    "        top_counts = total_counts[:max_value-1]\n",
    "        \n",
    "        # Define the cutoff\n",
    "        cutoff_value = top_counts.iloc[-1]\n",
    "        \n",
    "        # Create a list of values to replace\n",
    "        replace_values = total_counts.loc[total_counts.values < cutoff_value].index\n",
    "        \n",
    "        # Replace in dataframe\n",
    "        for value in replace_values:\n",
    "            df[col] = df[col].replace(value, \"Other\")\n",
    "        \n",
    "        # Check to make sure binning was successful\n",
    "        print(df[col].value_counts())\n",
    "        print(f'Number of unique values: {df[col].nunique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2083854-4ed1-4dd7-81b0-d04e8798ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Choose activation function in hidden layers\n",
    "    activation_first_hidden = hp.Choice('activation_layer_0', activation_functions)\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units = hp.Int(\n",
    "            'units_layer_0',\n",
    "            min_value = 1,\n",
    "            max_value = max_num_neurons,\n",
    "            step = step_count),\n",
    "        activation = activation_first_hidden,\n",
    "        # kernel_regularizer = tf.keras.regularizers.L1(0.01),\n",
    "        input_dim = number_input_features\n",
    "    ))\n",
    "    \n",
    "    # # Tune whether to use dropout based on the Boolean hyperparameter\n",
    "    # if hp.Boolean(\"use_dropout\"):\n",
    "    #     # Add a dropout layer if the Boolean hyperparameter is True\n",
    "    #     nn_model.add(layers.Dropout(rate=0.5))  # Adjust the dropout rate as needed\n",
    "    \n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    num_layers = hp.Int('num_layers', 1, max_hidden_layers-1) # options: 1, 2\n",
    "    \n",
    "    for i in range(1, num_layers+1): # i-values: 1, 2 only\n",
    "        # Choose the number of neurons per layer\n",
    "        units_layer_i = hp.Int(\n",
    "            f'units_layer_{i}',\n",
    "            min_value = 1,\n",
    "            max_value = max_num_neurons,\n",
    "            step = step_count\n",
    "        )\n",
    "        \n",
    "        # Choose a different activation function for each layer\n",
    "        activation_layer_i = hp.Choice(f'activation_layer_{i}', activation_functions)\n",
    "\n",
    "        nn_model.add(tf.keras.layers.Dense(\n",
    "            units = units_layer_i,\n",
    "            activation = activation_layer_i\n",
    "        ))\n",
    "        \n",
    "        # # Tune whether to use dropout based on the Boolean hyperparameter\n",
    "        # if hp.Boolean(\"use_dropout\"):\n",
    "        #     # Add a dropout layer if the Boolean hyperparameter is True\n",
    "        #     nn_model.add(layers.Dropout(rate=0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "    # Add the output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units = 1,\n",
    "        activation = \"sigmoid\"\n",
    "    ))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(\n",
    "        loss = \"binary_crossentropy\",\n",
    "        optimizer = optimiser,\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbffc7-99d4-4ce5-8b06-e29edf322a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
